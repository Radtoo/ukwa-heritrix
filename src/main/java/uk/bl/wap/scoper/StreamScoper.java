/**
 * 
 */
package uk.bl.wap.scoper;

import java.io.IOException;

import org.springframework.context.support.AbstractApplicationContext;
import org.springframework.context.support.FileSystemXmlApplicationContext;

/**
 * This class takes a Heritrix3 scope configuration file and runs it as a
 * standalone application. This allows scope processing to be handled outside of
 * the crawl download process.
 * 
 * The idea is that there would be two incoming Kafka queues:
 * 
 * 1. to.launch (1 partition)
 * 
 * 2. to.scope (many partitions)
 * 
 * The former is read by all StreamScoper instances, and it used to update
 * configurations and initiate crawls. The latter is a stream of candidate URLs
 * generated by crawling activity, but which may contain duplicate and
 * out-of-scope items.
 * 
 * For a given crawl stream, the StreamScoper reads a subset of the to.scope
 * queue and drops out-of-scope URLs and duplicate submissions (if the re-appear
 * within the minimum re-crawl period for that site). The URIs that remain are
 * posted to a to.crawl queue for downloading.
 * 
 * If new crawl launches come in via the to.launch stream, any configuration
 * changes are applied (i.e. sheet associates), before being handled as normal.
 * This separation keeps the launches separate and ensures any configuration
 * updates are distributed to all StreamScoper instances.
 * 
 * ----
 * 
 * For the first version of this, it is sufficient to just filter the to.scope
 * feed, so that the 2018 domain crawl can proceed more efficiently.
 * 
 * We could use a Bloom filter but this are difficult to persist and share
 * across instances, which makes them hard to scale. The alternative are to:
 * 
 * 1. Mix discovered-URIs in with downloaded URIs in the same OutbackCDX
 * instance.
 * 
 * 2. Use a separate OutbackCDX collection for discovered URIs.
 * 
 * 3. Switch to a new PGSQL/CRDB database for recording URI status.
 * 
 * Longer term, 3 looks better, but short-term, 2 is probably for the best.
 * 
 * For 1 or 2, we need a process that checks for candidate URIs in OutbackCDX.
 * This is basically the RecentlySeenUriUniqFilter code, but run outside of the
 * frontier.
 * 
 * @author Andrew Jackson <Andrew.Jackson@bl.uk>
 *
 */
public class StreamScoper {

    /**
     * @param args
     * @throws IOException
     * @throws InterruptedException
     */
    public static void main(String[] args)
            throws IOException, InterruptedException {

        // Start up the application, as per the Spring configuration:
        AbstractApplicationContext springContext = new FileSystemXmlApplicationContext(
                "scope.xml");
        springContext.start();

        while (true) {

        }

    }

}
